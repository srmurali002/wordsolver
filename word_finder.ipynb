{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_finder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXiAHROWWqzE",
        "outputId": "09f9ad7d-bdd2-4e98-dc47-ba1eb2f0ac69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjDvqJ0qGOwf"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk import word_tokenize, pos_tag\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"test\"\n",
        "print(wordnet.synsets(word))\n",
        "print(wordnet.synsets(word)[1].name())\n",
        "print(wordnet.synsets(word)[1].definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rbhQLKyFbIx",
        "outputId": "61cf413d-7cdc-4ecc-861d-041796f24743"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('trial.n.02'), Synset('test.n.02'), Synset('examination.n.02'), Synset('test.n.04'), Synset('test.n.05'), Synset('test.n.06'), Synset('test.v.01'), Synset('screen.v.01'), Synset('quiz.v.01'), Synset('test.v.04'), Synset('test.v.05'), Synset('test.v.06'), Synset('test.v.07')]\n",
            "test.n.02\n",
            "any standardized procedure for measuring sensitivity or memory or intelligence or aptitude or personality etc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Similarity score based on wordnet corpus"
      ],
      "metadata": {
        "id": "l14zKogTpiZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def penn_to_wn(tag):\n",
        "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
        "    if tag.startswith('N'):\n",
        "        return 'n'\n",
        " \n",
        "    if tag.startswith('V'):\n",
        "        return 'v'\n",
        " \n",
        "    if tag.startswith('J'):\n",
        "        return 'a'\n",
        " \n",
        "    if tag.startswith('R'):\n",
        "        return 'r'\n",
        " \n",
        "    return None\n",
        " \n",
        "def tagged_to_synset(word, tag):\n",
        "    wn_tag = penn_to_wn(tag)\n",
        "    if wn_tag is None:\n",
        "        return None\n",
        " \n",
        "    try:\n",
        "        return wordnet.synsets(word, wn_tag)[0]\n",
        "    except:\n",
        "        return None\n",
        " \n",
        "def sentence_similarity(sentence1, sentence2):\n",
        "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
        "    # Tokenize and tag\n",
        "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
        "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
        " \n",
        "    # Get the synsets for the tagged words\n",
        "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
        "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
        " \n",
        "    # Filter out the Nones\n",
        "    synsets1 = [ss for ss in synsets1 if ss]\n",
        "    synsets2 = [ss for ss in synsets2 if ss]\n",
        " \n",
        "    score, count = 0.0, 0\n",
        " \n",
        "    # For each word in the first sentence\n",
        "    for synset in synsets1:\n",
        "        # Get the similarity value of the most similar word in the other sentence\n",
        "        best_score = max([synset.path_similarity(ss) for ss in synsets2])\n",
        " \n",
        "        # Check that the similarity could have been computed\n",
        "        if best_score is not None:\n",
        "            score += best_score\n",
        "            count += 1\n",
        " \n",
        "    # Average the values\n",
        "    score /= count\n",
        "    return score"
      ],
      "metadata": {
        "id": "ie0JEFgDJEXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search algo fn: searcher(maskedword, meaning of word, similarity threshold) Based on Wordnet corpus"
      ],
      "metadata": {
        "id": "DDFginNbpqko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def searcher(masked, meaning, sim_thr = 0.8):\n",
        "\n",
        "    wlist = [ n for n in wordnet.all_lemma_names() if (len(n) == len(masked))]\n",
        "\n",
        "    words = [n for n in wlist if len(n) == len(masked)]\n",
        "\n",
        "    def ord_list(word): return [ord(c) for c in list(word)]\n",
        "\n",
        "    diffs = []\n",
        "\n",
        "    no_chars = sum([int(c.isalpha()) for c in masked])\n",
        "\n",
        "    for word in words:\n",
        "        diffs.append([i-j for i,j in zip(ord_list(masked),ord_list(word))])\n",
        "        \n",
        "    diffs = np.array(diffs)\n",
        "    ids = np.argwhere(np.count_nonzero(diffs==0, axis=1) == no_chars).ravel()\n",
        "\n",
        "    search_result = [words[i] for i in ids]\n",
        "\n",
        "    max_prob = []\n",
        "    for item in search_result:\n",
        "      word = item\n",
        "      syns = wordnet.synsets(word)\n",
        "      syn_wor_list = np.array([syn.name().split(\".\")[0].replace('_',' ') for syn in syns])\n",
        "      ids = np.argwhere(syn_wor_list == word).ravel()\n",
        "      for i in ids:\n",
        "        defin = syns[i].definition()\n",
        "        if defin:\n",
        "          if sentence_similarity(defin,meaning) >= sim_thr:\n",
        "            max_prob.append(item)\n",
        "\n",
        "    return list(set(max_prob))"
      ],
      "metadata": {
        "id": "GzGp5zRDW1s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "xmxephjQpy47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masked = \"t--t\"\n",
        "meaning = \"the words of something written\"\n",
        "sim_thr = 0.8"
      ],
      "metadata": {
        "id": "XG3mDlAypxJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "searcher(masked,meaning,sim_thr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3pR3A0FoNZM",
        "outputId": "88e2026e-1410-4714-e54f-4ba292b56670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}